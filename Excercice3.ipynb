{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Exercise 3 : Text classification on the Ohsumed dataset\n",
    "\n",
    "The goal of this exercise is to realize a text classifier using deep neural networks. Your task is to construct a classifier, using the available training set, and evaluate it using the test set. The classifier should predict the category for the articles.\n",
    "\n",
    "Dataset : We will work with the Ohsumed dataset that contains abstracts of scientific articles from a large medical publication database. The articles are related to one of 23 categories of cardiovascular diseases. ```IMDB_Dataset.zip```\n",
    "\n",
    "Dataset description : The dataset has two versions :\n",
    "- One that contains the first 20000 articles (split into training and test set), available on Moodle ;\n",
    "- A more complete version that has all articles (50000 articles), available here.\n",
    "\n",
    "You should work with the version that has 20000 articles, and only use the complete version only once you constructed and analyzed an efficient classifier for the smaller set. As usual, the dataset is split into two parts : a training set and a test set. Each article of the collection is labeled with one of the 23 categories. \n",
    "\n",
    "Overall strategy : To realize a classifier you should use an iterative approach : try to realize a simple classifier first, then analyze its performances (e.g. using the accuracy metric), then chose techniques to improve the performance (in terms of accuracy) of your classifier. \n",
    "\n",
    "Try to describe and document the development process in your report : which experiments did you run ? What were the results ? What did you\n",
    "do to improve the performance and why ?\n",
    "To implement your first text classifier from scratch, we advise you to :\n",
    "- Look into the data, get familiar with its structure and the type of text you will process ;\n",
    "- Explore the data and compute some basic statistics. For example, what is the size of the vocabulary ?\n",
    "\n",
    "What is the number of examples in the training/test set per category ? What is the frequency of the words ? What is the most common, the least common ? Feel free to add anything you find relevant on the dataset ;\n",
    "\n",
    "- Preprocessing : adjust your data to be able to pass them into a neural network ;\n",
    "- Create a neural network with a simple architecture and train it ;\n",
    "- Evaluate the performance of your classifier on the training set and the test set. These numbers can give hints about the quality of your classifier and can also can guide you to decide what to do in order to improve the performance. Beware of under-fitting and over-fitting ;\n",
    "- Interpret your results (in plain text) and set your next objective (for example, if you had an over-fitting and you decide to add regularization, explain it) ;\n",
    "- Iterate (many many many times) and try to improve your model. Tunning a network is sometimes difficult due to all the possibilities for the hyper-parameters. \n",
    "\n",
    "In order to improve your network during your iterations, you can try to :\n",
    "- Invest time to do more preprocessing. For example, remove frequent words, remove stopwords, perform stemming. A quick introduction here ;\n",
    "- Change the parameters of your algorithms and your optimizers, cost functions, etc ;\n",
    "- Add dropout, early stopping, regularization ;\n",
    "- Change the network topology/use different techniques (multilayer perceptron, LSTM, etc) ;\n",
    "- Only when you managed to obtain good results, witch to the bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
